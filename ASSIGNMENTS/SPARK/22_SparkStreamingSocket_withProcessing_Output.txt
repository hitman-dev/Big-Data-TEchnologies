

22_SparkStreamingSocket_withProcessing.py
---------------------------------------------------------------------------------
OUTPUT:-
---------------------------------------------------------------------------------

/home/hitman/DBDA_HOME/DBDA_CODE/SPARK/PYTHON/venv/bin/python /home/hitman/DBDA_HOME/DBDA_CODE/SPARK/PYTHON/streaming/22_SparkStreamingSocket_withProcessing.py
Create the spark session
22/01/17 15:54:40 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.0.106 instead (on interface wlp2s0)
22/01/17 15:54:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hitman/DBDA_HOME/DBDA_CODE/SPARK/PYTHON/venv/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
22/01/17 15:54:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/01/17 15:54:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
22/01/17 15:54:43 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.
Check the schema for the lines dataframe
root
 |-- value: string (nullable = true)

Check the schema for the words dataframe
root
 |-- word: string (nullable = true)

Check the schema for the wc dataframe
root
 |-- word: string (nullable = true)
 |-- count: long (nullable = false)

22/01/17 15:54:46 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-fead349d-747e-43b0-998e-899a928b61a2. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.
22/01/17 15:54:46 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
-------------------------------------------
Batch: 0
-------------------------------------------
+----+-----+
|word|count|
+----+-----+
+----+-----+

-------------------------------------------
Batch: 1
-------------------------------------------
+---------+-----+
|     word|count|
+---------+-----+
|      for|    1|
|    hello|    1|
|    count|    1|
|streaming|    1|
|       is|    1|
|    ,this|    1|
|    spark|    1|
|     word|    1|
|  running|    1|
+---------+-----+

-------------------------------------------
Batch: 2
-------------------------------------------
+----------+-----+
|      word|count|
+----------+-----+
|       for|    1|
|     hello|    1|
|     count|    1|
| streaming|    1|
|successful|    1|
|        is|    1|
| execution|    1|
|     ,this|    1|
|     spark|    1|
|      word|    1|
|   running|    1|
+----------+-----+

-------------------------------------------
Batch: 3
-------------------------------------------
+----------+-----+
|      word|count|
+----------+-----+
|       for|    1|
|     hello|    1|
|     count|    1|
| streaming|    1|
|successful|    1|
|        is|    1|
| execution|    1|
|     ,this|    1|
|     spark|    1|
|       bye|    2|
|      word|    1|
|   running|    1|
+----------+-----+

22/01/17 15:56:37 WARN TextSocketMicroBatchStream: Stream closed by localhost:9999
